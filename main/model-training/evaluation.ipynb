{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 512\n",
    "VAL_SPLIT = 0.2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to measure inference time in seconds\n",
    "def measure_inference_time(model, dataset):\n",
    "    total_time = tf.constant(0.0)\n",
    "    total_images = tf.constant(0)\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        start_time = float(tf.timestamp())\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        end_time = float(tf.timestamp())\n",
    "\n",
    "        batch_time = end_time - start_time\n",
    "        total_time += batch_time\n",
    "        total_images += images.shape[0]\n",
    "\n",
    "    avg_time_per_image = total_time / tf.cast(total_images, tf.float32)\n",
    "    return avg_time_per_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 files belonging to 2 classes.\n",
      "Using 32 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '../../data-collection/image-backend/saved_images'\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=['hazard', 'non-hazard'],\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNET B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net = tf.keras.models.load_model('../models/EfficientNET.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 10s/step - accuracy: 0.9167 - loss: 0.3462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.90625, 'loss': 0.3845493793487549}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficient_net.evaluate(test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per image: 0.541002 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 08:48:33.704912: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "avg_time_efficientnet = measure_inference_time(efficient_net, test_dataset)\n",
    "print(f\"Average inference time per image: {avg_time_efficientnet:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.models.load_model('../models/ResNet.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - binary_accuracy: 0.7708 - loss: 0.4548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': 0.8125, 'loss': 0.4045429229736328}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.evaluate(test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 08:48:50.249758: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per image: 0.272248 seconds\n"
     ]
    }
   ],
   "source": [
    "avg_time_resnet = measure_inference_time(resnet, test_dataset)\n",
    "print(f\"Average inference time per image: {avg_time_resnet:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = tf.keras.models.load_model('../models/VGG16.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12s/step - binary_accuracy: 0.4583 - loss: 0.9235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': 0.53125, 'loss': 0.852462887763977}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.evaluate(test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per image: 0.690496 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 08:50:52.694601: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "avg_time_vgg = measure_inference_time(vgg16, test_dataset)\n",
    "print(f\"Average inference time per image: {avg_time_vgg:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = tf.keras.models.load_model('../models/Xception.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step - accuracy: 0.4167 - loss: 9.4022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4375, 'loss': 9.066429138183594}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception.evaluate(test_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average inference time per image: 0.330446 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 08:50:03.362128: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "avg_time_xception = measure_inference_time(xception, test_dataset)\n",
    "print(f\"Average inference time per image: {avg_time_xception:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
